{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heterogenous grapgh learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Heterogeneous Graph Learning\n",
        "In this notebook, we will explore how to train a GNN model with heterogeneous graph data. In real world, most of the graph data is available in the form of different node and edge type."
      ],
      "metadata": {
        "id": "kJvQ8_y292zz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsudzf_U9c4g",
        "outputId": "04de4e6a-a87c-4f3b-ec22-192a9e927c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 11.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 10.0 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric\n",
        "from torch_geometric.data import HeteroData\n",
        "import os\n",
        "import os.path as osp\n",
        "from typing import Dict, List, Union\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import IMDB\n",
        "from torch_geometric.nn import HANConv\n"
      ],
      "metadata": {
        "id": "Hv7vqpBC-0Jp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = osp.join(osp.dirname(osp.realpath('__file__')), '../../data/IMDB')\n",
        "\n",
        "metapaths = [[('movie', 'actor'), ('actor', 'movie')],\n",
        "             [('movie', 'director'), ('director', 'movie')]]\n",
        "transform = T.AddMetaPaths(metapaths= metapaths, drop_orig_edges= True, drop_unconnected_nodes= True)\n",
        "dataset = IMDB(path, transform = transform)\n",
        "data = dataset[0]\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecv7x3lA_OEt",
        "outputId": "d1cc200f-1e14-467b-9c04-b732377c3df5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.dropbox.com/s/g0btk9ctr1es39x/IMDB_processed.zip?dl=1\n",
            "Extracting /data/IMDB/raw/IMDB_processed.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  metapath_dict={\n",
            "    (movie, metapath_0, movie)=[2],\n",
            "    (movie, metapath_1, movie)=[2]\n",
            "  },\n",
            "  \u001b[1mmovie\u001b[0m={\n",
            "    x=[4278, 3066],\n",
            "    y=[4278],\n",
            "    train_mask=[4278],\n",
            "    val_mask=[4278],\n",
            "    test_mask=[4278]\n",
            "  },\n",
            "  \u001b[1m(movie, metapath_0, movie)\u001b[0m={ edge_index=[2, 85358] },\n",
            "  \u001b[1m(movie, metapath_1, movie)\u001b[0m={ edge_index=[2, 17446] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define HAN conv\n",
        "class HAN(nn.Module):\n",
        "  def __init__(self, in_channels: Union[int, Dict[str, int]],\n",
        "               out_channels: int, hidden_channels = 128, heads=8):\n",
        "    super().__init__()\n",
        "\n",
        "    self.han_conv = HANConv(in_channels, hidden_channels, heads = heads, \n",
        "                            dropout = 0.6, metadata = data.metadata())\n",
        "    self.lin = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "  def forward(self, x_dict, edge_index_dict):\n",
        "    x = self.han_conv(x_dict, edge_index_dict)\n",
        "    x = self.lin(x['movie'])\n",
        "    return x\n",
        "model = HAN(in_channels= -1, out_channels= 3)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1wbHNoLCG-G",
        "outputId": "89feaa4b-5ab1-41ed-f30b-7a5e7ab034fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HAN(\n",
            "  (han_conv): HANConv(128, heads=8)\n",
            "  (lin): Linear(in_features=128, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HAN(in_channels= -1, out_channels =3)\n",
        "data, model = data.to(device), model.to(device)\n",
        "with torch.no_grad():\n",
        "  out = model(data.x_dict, data.edge_index_dict)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, weight_decay= 0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "__pzt7z5nTh_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train() -> float:\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  out = model(data.x_dict, data.edge_index_dict)\n",
        "  mask = data['movie'].train_mask\n",
        "  loss = criterion(out[mask], data['movie'].y[mask])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return float(loss)"
      ],
      "metadata": {
        "id": "fp3ltKjNnTUw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test() -> List[float]:\n",
        "  model.eval()\n",
        "  pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
        "\n",
        "\n",
        "  accs = []\n",
        "  for split in ['train_mask', 'val_mask', 'test_mask']:\n",
        "    mask = data['movie'][split]\n",
        "    acc = ((pred[mask] == data['movie'].y[mask]).sum())/mask.sum()\n",
        "    accs.append(float(acc))\n",
        "  return accs"
      ],
      "metadata": {
        "id": "Xor5HYraDLXG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = 0\n",
        "start_patience = patience = 100\n",
        "for epoch in range(1, 200):\n",
        "\n",
        "    loss = train()\n",
        "    train_acc, val_acc, test_acc = test()\n",
        "    if epoch % 10 == 0:\n",
        "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
        "          f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
        "\n",
        "    if best_val_acc <= val_acc:\n",
        "        patience = start_patience\n",
        "        best_val_acc = val_acc\n",
        "    else:\n",
        "        patience -= 1\n",
        "\n",
        "    if patience <= 0:\n",
        "        print('Stopping training as validation accuracy did not improve '\n",
        "              f'for {start_patience} epochs')\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74c115BlDg9P",
        "outputId": "58619d97-3fa4-4c51-e1aa-7e7b309f0d96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 0.0402, Train: 0.9900, Val: 0.5175, Test: 0.4879\n",
            "Epoch: 020, Loss: 0.0387, Train: 0.9900, Val: 0.5100, Test: 0.4911\n",
            "Epoch: 030, Loss: 0.0413, Train: 0.9900, Val: 0.5100, Test: 0.4908\n",
            "Epoch: 040, Loss: 0.0383, Train: 0.9900, Val: 0.5150, Test: 0.4917\n",
            "Epoch: 050, Loss: 0.0357, Train: 0.9900, Val: 0.5125, Test: 0.4905\n",
            "Epoch: 060, Loss: 0.0376, Train: 0.9900, Val: 0.5150, Test: 0.4862\n",
            "Epoch: 070, Loss: 0.0339, Train: 0.9900, Val: 0.5125, Test: 0.4899\n",
            "Epoch: 080, Loss: 0.0331, Train: 0.9900, Val: 0.5200, Test: 0.4945\n",
            "Epoch: 090, Loss: 0.0342, Train: 0.9900, Val: 0.5100, Test: 0.4948\n",
            "Epoch: 100, Loss: 0.0343, Train: 0.9900, Val: 0.5200, Test: 0.4991\n",
            "Epoch: 110, Loss: 0.0345, Train: 0.9900, Val: 0.5050, Test: 0.4899\n",
            "Epoch: 120, Loss: 0.0337, Train: 0.9900, Val: 0.5075, Test: 0.4885\n",
            "Epoch: 130, Loss: 0.0339, Train: 0.9900, Val: 0.5200, Test: 0.4928\n",
            "Epoch: 140, Loss: 0.0340, Train: 0.9900, Val: 0.5150, Test: 0.4905\n",
            "Epoch: 150, Loss: 0.0320, Train: 0.9900, Val: 0.5225, Test: 0.4891\n",
            "Epoch: 160, Loss: 0.0327, Train: 0.9900, Val: 0.5150, Test: 0.4951\n",
            "Epoch: 170, Loss: 0.0321, Train: 0.9900, Val: 0.5150, Test: 0.4945\n",
            "Epoch: 180, Loss: 0.0329, Train: 0.9900, Val: 0.5175, Test: 0.4954\n",
            "Epoch: 190, Loss: 0.0335, Train: 0.9900, Val: 0.5100, Test: 0.4908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EDgAQAuoFgZd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}